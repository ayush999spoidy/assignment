# -*- coding: utf-8 -*-
"""statistics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvgwIPxbKncLy5QdLtEPiL8pTaVz3N3d

1. Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss
nominal, ordinal, interval, and ratio scales.

Ans.Qualitative Data: Descriptive and categorical data that represents characteristics or attributes, often expressed in words rather than numbers.
Key Features: Non-numerical, cannot be measured, but can be observed or categorized.
Examples:
Colors of cars in a parking lot (e.g., red, blue, black).
Gender (e.g., male, female, non-binary).

Quantitative Data:Numerical data that represents measurable quantities and can be counted or calculated.
Key Features: Numerical, can be discrete or continuous.
Discrete: Countable values
(ex= the number of books on a shelf, the number of students in a class).
Continuous: Values within a range
(ex= height, weight, temperature).

Nominal Scale: Represents data as categories without a specific order.
Characteristics:
Categories are mutually exclusive.
No intrinsic ranking or numerical value.

Ordinal Scale:Represents categories with a meaningful order or ranking, but the intervals between categories are not consistent.

Interval Scale: Numerical data with equal intervals between values but no true zero point.
Characteristics:
Differences between values are meaningful.
Ratios cannot be calculated because zero is arbitrary.

Ratio Scale: Numerical data with equal intervals and a true zero point, allowing for meaningful ratios.
Characteristics:
Differences and ratios between values are meaningful.
Zero means the absence of the quantity.

2. What are the measures of central tendency, and when should you use each? Discuss the mean, median,
and mode with examples and situations where each is appropriate.

Ans.Measures of central tendency describe the "center" or typical value of a data set. The three primary measures are mean, median, and mode. Each has specific uses and is appropriate in different situations depending on the nature of the data and the question being addressed.

Mean= The mean is the sum of all the values in a dataset divided by the number of values.

Median= The median is the middle value in an ordered dataset. If the dataset has an even number of values, the median is the average of the two middle values.

Mode= The mode is the most frequently occurring value(s) in a dataset. A dataset can have no mode, one mode, or multiple modes (bimodal, multimodal).
"""

import numpy as np
import pandas as pd

dataset=pd.read_csv("titanic.csv")
dataset.head(3)

dataset["Age"].mean()

de=np.mean(dataset["Age"])

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(x="Fare",data=dataset,bins=[i for i in range(0,81,10)])
plt.plot([de for i in range(0,300)],[i for i in range(0,300)])
plt.show()

np.median(dataset["Fare"])

sd=dataset["Fare"].median()

sd

sns.histplot(x="Fare",data=dataset,bins=[i for i in range(0,81,10)])
plt.plot([sd for i in range(0,300)],[i for i in range(0,300)],c="red")
plt.show()

dataset["Fare"].mode()

mo=dataset["Pclass"].mode()[0]

mo

sns.histplot(x="Pclass",data=dataset,bins=[i for i in range(0,81,10)])
plt.plot([sd for i in range(0,300)],[i for i in range(0,300)],c="Yellow")
plt.show()

"""3. Explain the concept of dispersion. How do variance and standard deviation measure the spread of data?

Ans.Dispersion refers to the extent to which data points in a dataset vary or spread out from a central value (such as the mean). It provides insight into the variability or consistency within the data. A dataset with low dispersion has values tightly clustered around the center, while a dataset with high dispersion has values spread widely.

Range: The difference between the maximum and minimum values.
Variance: The average of the squared differences between each data point and the mean.
Standard Deviation: The square root of the variance, indicating the average distance of data points from the mean.

Variance:

It focuses on the squared deviations, giving more weight to extreme values (outliers) due to squaring.
Useful for statistical methods that require squared deviations (e.g., in regression analysis or ANOVA).


Standard Deviation:

It is more interpretable for practical purposes because it has the same units as the data.
It shows the typical deviation from the mean, providing a direct sense of the variability in the dataset.

4.What is a box plot, and what can it tell you about the distribution of data?

Ans.A box plot is a graphical representation of the distribution of a dataset. It provides a visual summary of the data central tendency, spread, and potential outliers. Box plots are particularly useful for comparing distributions across different groups.

Central Tendency:The median line inside the box gives an idea of the data's central value.


Spread:The length of the box (IQR) shows the variability in the middle 50% of the data.
The whiskers give a sense of the overall spread, excluding outliers.


Skewness:If the median is closer to the bottom or top of the box, the data is skewed.
Longer whiskers on one side indicate skewness in that direction.


Outliers:Points outside the whiskers signal unusual or extreme values.


Comparison:When plotting multiple box plots side by side, you can easily compare distributions between different groups

5. Discuss the role of random sampling in making inferences about populations.

Ans. Random sampling is a fundamental method in statistics used to select a subset (sample) of individuals or observations from a larger population. It ensures that every member of the population has an equal chance of being included in the sample, thereby reducing bias and allowing researchers to make reliable inferences about the population.

Random sampling is crucial for making valid and reliable inferences about populations. It ensures representativeness, reduces bias, and allows the application of statistical techniques to estimate population parameters and test hypotheses. However, it must be implemented carefully to account for practical challenges and potential errors.

6.Explain the concept of skewness and its types. How does skewness affect the interpretation of data?

Ans.Skewness measures the asymmetry of a dataset's distribution around its mean. A distribution is considered symmetric if it looks the same to the left and right of the center point. Skewness indicates whether the data tails off more significantly in one direction than the other.

Positive Skewness (Right-Skewed Distribution):

The tail is longer on the right (toward higher values).
Most data points are clustered on the lower end, with a few extreme values on the higher end.
Mean > Median > Mode.
Example: Income distribution, where most people earn moderate incomes, but a few earn extremely high incomes.

Negative Skewness (Left-Skewed Distribution):

The tail is longer on the left (toward lower values).
Most data points are clustered on the higher end, with a few extreme values on the lower end.
Mean < Median < Mode.
Example: Age at retirement, where most people retire at older ages, but a few retire early.

Zero Skewness (Symmetric Distribution):

The data is perfectly symmetric around the mean.
Mean = Median = Mode.
Example: Heights of adult men in a population (approximately symmetric).


Central Tendency: In skewed distributions, the mean is pulled in the direction of the tail because it is sensitive to extreme values.
The median is more representative of the central tendency in skewed data, as it is less influenced by outliers.

Spread:Skewness affects the perception of variability and spread. Positively skewed data might appear more spread out on the right, and negatively skewed data on the left.


Data Interpretation:In a right-skewed distribution, the majority of values fall below the mean. For example, when interpreting income data, the mean income may appear higher due to a few very high earners.
In a left-skewed distribution, most values are above the mean, making the data look more concentrated at the higher end.


Statistical Assumptions:Many statistical methods, like t-tests and ANOVA, assume normality (symmetry). Skewed data may require transformations (e.g., logarithmic or square root) or non-parametric methods to meet these assumptions.


Decision-Making:Skewness highlights the presence of outliers or unusual patterns in data, guiding appropriate statistical techniques and realistic interpretations.

7.What is the interquartile range (IQR), and how is it used to detect outliers?

Ans.The interquartile range (IQR) is a measure of statistical dispersion, representing the range within which the central 50% of a dataset falls. It is calculated as the difference between the third quartile (
𝑄
3
Q3) and the first quartile (
𝑄
1
Q1):

IQR
=
𝑄
3
−
𝑄
1
IQR=Q3−Q1
Q1 (First Quartile): The value below which 25% of the data falls.
Q3 (Third Quartile): The value below which 75% of the data falls.


Outliers are data points that lie significantly outside the typical range of the data. The IQR is often used to define boundaries for identifying outliers.

Determine the Upper and Lower Bounds:

Lower Bound:
𝑄
1
−
1.5
×
IQR
Q1−1.5×IQR
Upper Bound:
𝑄
3
+
1.5
×
IQR
Q3+1.5×IQR
Identify Outliers:

Data points below the lower bound or above the upper bound are considered outliers.

8. Discuss the conditions under which the binomial distribution is used.

Ans.The binomial distribution is used to model the probability of a fixed number of successes in a fixed number of independent trials, where each trial has two possible outcomes: success or failure. It is commonly used in scenarios where there are repeated experiments or trials, and each trial has the same probability of success.


Fixed Number of Trials (n):The number of trials or experiments is fixed in advance.
Example: Flipping a coin 10 times.


Two Possible Outcomes (Success or Failure):Each trial results in one of two outcomes: success or failure. These outcomes are typically labeled "success" (often denoted as
𝑆
S) and "failure" (denoted as
𝐹
F).
Example: In a survey, "yes" could be a success, and "no" a failure.


Constant Probability of Success (p):The probability of success,
𝑝
p, is the same for each trial. The probability of failure is
1
−
𝑝
1−p.
Example: If the probability of getting heads in a coin flip is 0.5, that probability remains constant for each flip.


Independence of Trials:The outcome of each trial is independent of the others. The result of one trial does not affect the outcome of any other trial.
Example: Whether the first flip of a coin is heads or tails does not influence the result of the second flip.


Random Sampling (or Random Assignment):The trials should be conducted randomly, and the outcome of each trial is not influenced by any external factors.

9. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).

Ans. The normal distribution is a symmetric, bell-shaped probability distribution that is widely used in statistics due to its natural occurrence in various fields like finance, biology, and social sciences. It is often referred to as the Gaussian distribution. A normal distribution is characterized by the following properties:

Symmetry:

The normal distribution is perfectly symmetric around its mean (
𝜇
μ). This means the left and right sides of the distribution are mirror images of each other.
The mean (
𝜇
μ), median, and mode of a normal distribution are all equal and located at the center of the distribution.
Bell-Shaped Curve:

The shape of the normal distribution is bell-shaped, with the peak occurring at the mean (
𝜇
μ).
As you move away from the mean in either direction, the frequency of occurrences decreases, tapering off asymptotically towards the horizontal axis (but never quite touching it).
Defined by Mean and Standard Deviation:

A normal distribution is fully described by two parameters: the mean (
𝜇
μ) and the standard deviation (
𝜎
σ).
The mean determines the center of the distribution.
The standard deviation measures the spread or dispersion of the data. A larger standard deviation means a wider, flatter curve, while a smaller standard deviation results in a narrower, steeper curve.


68-95-99.7 Rule (Empirical Rule):

The empirical rule describes the percentage of data that falls within one, two, and three standard deviations from the mean in a normal distribution. Specifically:
68% of the data falls within 1 standard deviation of the mean.
95% of the data falls within 2 standard deviations of the mean.
99.7% of the data falls within 3 standard deviations of the mean.


Asymptotic:

The tails of the normal distribution extend infinitely in both directions and approach, but never actually touch, the horizontal axis.
This means that there is a small (but non-zero) probability of extreme values occurring far from the mean.


Area under the Curve:

The total area under the normal distribution curve is equal to 1 (or 100%). This represents the total probability for all possible outcomes in the distribution.


The 68-95-99.7 Rule:

The empirical rule is a specific characteristic of the normal distribution, which gives us an intuitive understanding of the

distribution of data:
68% of the data lies within 1 standard deviation of the mean. This is the middle section of the curve.
95% of the data lies within 2 standard deviations of the mean. This covers most of the data, including the tails.
99.7% of the data lies within 3 standard deviations of the mean. This essentially covers nearly all of the data, leaving out only extreme outliers.

10. Provide a real-life example of a Poisson process and calculate the probability for a specific event.

Ans.A Poisson process models the occurrence of events that happen randomly and independently over a fixed period of time or space. It is typically used to describe situations where events occur at a constant average rate but are spread out unpredictably over time or space.

Example: Call Center
Consider a call center where calls arrive randomly throughout the day. On average, the center receives 5 calls per hour. We want to calculate the probability of receiving exactly 3 calls in a given hour.
"""

from scipy.stats import poisson
import matplotlib.pyplot as plt

from scipy.stats import poisson

# Define the average rate (lambda)
mu = 60

# Calculate the probability of exactly 20 events
probability = poisson.pmf(50, mu)

print(f"The probability of receiving exactly 20 calls in an hour is: {probability:.4f}")

plt.hist(poisson.pmf(range(0,30),mu))
plt.show()



"""11. Explain what a random variable is and differentiate between discrete and continuous random variables.

Ans. A random variable is a variable that represents the outcome of a random phenomenon or experiment. It is a numerical value that is assigned to each possible outcome in a sample space, and its value is determined by the outcome of a random event. Random variables can be classified into two types: discrete and continuous.

Discrete Random Variable: Takes a finite or countably infinite number of distinct values.	Discrete Random Variables are often shown using a bar graph where the x-axis represents the possible values, and the y-axis represents the probability of each value.


Continuous Random Variable: Takes an infinite number of possible values within a range.Continuous Random Variables are represented using a curve (PDF), where the area under the curve over an interval represents the probability of the variable falling within that interval.

12. Provide an example dataset, calculate both covariance and correlation, and interpret the results

Ans
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

na=pd.read_csv("tips.csv")
na.head(3)

na.isnull().sum()

na.info()

na.select_dtypes(["float64","int64"]).corr()

n=na.select_dtypes(["float64","int64"]).corr()

n

s=na.select_dtypes(["float64","int64"]).cov()

s

plt.figure(figsize=(3,4))
sns.heatmap(n,annot=True)
plt.show()

plt.figure(figsize=(3,4))
sns.heatmap(s,annot=True)
plt.show()

