{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a Decision Tree, and how does it work."
      ],
      "metadata": {
        "id": "zP0hfLPisUZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.A decision tree is a supervised machine learning algorithm that can be used for both classification and regression tasks. It's a flowchart-like structure where each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (for classification) or a numerical value (for regression)\n",
        "\n",
        "\n",
        "\n",
        "Building the Tree:\n",
        "\n",
        "The algorithm starts with the entire dataset at the root node.\n",
        "It selects the best attribute to split the data based on a measure like Gini impurity or information gain.\n",
        "The data is divided into subsets based on the chosen attribute's values.\n",
        "This process is recursively applied to each subset, creating child nodes, until a stopping criterion is met (e.g., all data points in a node belong to the same class, or a maximum depth is reached).\n",
        "\n",
        "\n",
        "\n",
        "Making Predictions:\n",
        "\n",
        "To classify a new data point, it's traversed down the tree from the root node, following the branches based on the attribute values of the data point.\n",
        "When it reaches a leaf node, the class label or numerical value associated with that leaf is assigned as the prediction."
      ],
      "metadata": {
        "id": "KeyxEhEJsUPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What are impurity measures in Decision Trees."
      ],
      "metadata": {
        "id": "7xgzfit_syCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.In the context of decision trees, impurity measures are used to quantify the homogeneity of a set of data points in a node. A node is considered pure if all data points in it belong to the same class. Conversely, a node is impure if it contains data points from multiple classes."
      ],
      "metadata": {
        "id": "oNQB-3Dgsz4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What is the mathematical formula for Gini Impurity."
      ],
      "metadata": {
        "id": "H_Fl5RqZtNjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Gini Impurity = 1 - Σ (pi)^2"
      ],
      "metadata": {
        "id": "fZ7dMzxxtNyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What is the mathematical formula for Entropy."
      ],
      "metadata": {
        "id": "c3YMaxAptfpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Entropy = - Σ (pi * log2(pi))"
      ],
      "metadata": {
        "id": "RNsCJ6nrtgNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is Information Gain, and how is it used in Decision Trees."
      ],
      "metadata": {
        "id": "YMvtmL1CtsJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Information Gain is like a score that tells us how helpful a split is in making the data more organized. Decision Trees use this score to choose the best way to split the data at each step, aiming to create a tree that can accurately predict outcomes."
      ],
      "metadata": {
        "id": "0WTqnDVbtsuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is the difference between Gini Impurity and Entropy."
      ],
      "metadata": {
        "id": "WKvedNHWuBWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Gini Impurity is like measuring the chance of making a mistake when randomly guessing the color of a marble from a bag.\n",
        "Entropy is like measuring the \"messiness\" or \"disorder\" of a room."
      ],
      "metadata": {
        "id": "gHUzjmgYuByr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What is the mathematical explanation behind Decision Trees."
      ],
      "metadata": {
        "id": "W46A8z7ouTcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ans.Imagine sorting a deck of cards. You want to divide the cards into groups (hearts, diamonds, clubs, spades). You might start by splitting based on color (red or black), then further split based on suit symbols. Each split makes the groups more \"pure\" (containing mostly one type of card)."
      ],
      "metadata": {
        "id": "1MJC6HNyuTNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is Pre-Pruning in Decision Trees."
      ],
      "metadata": {
        "id": "OBArrQHFuqMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Pre-pruning is a valuable technique for controlling the complexity of decision trees and preventing overfitting. By setting limits during tree construction, it helps to create more robust and generalized models."
      ],
      "metadata": {
        "id": "HQ5upv_yuq5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Post-Pruning in Decision Trees."
      ],
      "metadata": {
        "id": "QvcQBlmZu4Bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Post-pruning, also known as backward pruning, is a technique used in decision tree learning to reduce overfitting by removing unnecessary branches or subtrees from a fully grown tree. Unlike pre-pruning, which stops tree growth early, post-pruning allows the tree to grow to its full depth and then trims it back based on its performance on a validation dataset."
      ],
      "metadata": {
        "id": "jcEZmKiGu4XA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What is the difference between Pre-Pruning and Post-Pruning."
      ],
      "metadata": {
        "id": "vX_pdUkLvIkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Pre-Pruning: Like preventing a tree from getting too big in the first place.\n",
        "Post-Pruning: Like cleaning up a tree that has already grown too wild."
      ],
      "metadata": {
        "id": "akUZqPlevJNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is a Decision Tree Regressor."
      ],
      "metadata": {
        "id": "EpPOf7KNvuAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.It's a type of Decision Tree used for predicting a continuous numerical value (like price, temperature, or age) instead of a category (like \"yes/no\" or \"red/blue/green\").\n",
        "It works by dividing the data into smaller groups based on different features, and then predicting the average value of the target variable within each group."
      ],
      "metadata": {
        "id": "uYddR2H8vufx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What are the advantages and disadvantages of Decision Trees."
      ],
      "metadata": {
        "id": "irRGSmXQwKZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Advantages:\n",
        "\n",
        "Easy to understand and interpret: They are visually intuitive and their logic is easy to follow.\n",
        "Versatile: Can handle both numerical and categorical data.\n",
        "Non-parametric: No assumptions about the data distribution.\n",
        "Feature importance: Provide insights into which features are most important for prediction.\n",
        "Fast prediction: Once the tree is built, predictions are quick.\n",
        "\n",
        "\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Prone to overfitting: Can become too complex and memorize the training data, leading to poor generalization.\n",
        "Instability: Small changes in data can lead to large changes in the tree structure.\n",
        "Bias towards dominant features: May favor features with many categories.\n",
        "Difficulty with complex relationships: May not capture complex interactions between features.\n",
        "Not always optimal: May not be the most accurate model for all datasets"
      ],
      "metadata": {
        "id": "vyjYL_O2wK6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.How does a Decision Tree handle missing values."
      ],
      "metadata": {
        "id": "skTJuQKewtDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Decision Trees handle missing values by either ignoring them, filling them in, or finding alternative ways to split the data. This allows the tree to be built and used for prediction even when some data is missing."
      ],
      "metadata": {
        "id": "DgL7bnb4wuE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.How does a Decision Tree handle categorical features."
      ],
      "metadata": {
        "id": "clsMrkkxw-f9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.category values. This eliminates the need for encoding and preserves the inherent information in the categorical data."
      ],
      "metadata": {
        "id": "AdAADHb8w-pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What are some real-world applications of Decision Trees."
      ],
      "metadata": {
        "id": "wmLK3AV5xXF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.Decision Trees are used in real life to help businesses understand their customers, prevent fraud, improve healthcare, and make better decisions in various areas."
      ],
      "metadata": {
        "id": "C1zLihbUxXei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gFKebbesEjH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ECHNG-4auqfh"
      }
    }
  ]
}